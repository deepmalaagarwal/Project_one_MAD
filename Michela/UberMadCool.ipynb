{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import pandas as pd\n",
    "import numpy as np # linear algebra\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from builtins import list\n",
    "import matplotlib\n",
    "matplotlib.style.use('ggplot')\n",
    "import scipy.stats as st\n",
    "import datetime\n",
    "from sklearn import datasets\n",
    "from scipy.stats import linregress\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "uber_csv = \"Resources/uber-rides-dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'Resources/uber-rides-dataset.csv' does not exist: b'Resources/uber-rides-dataset.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-c1c6b49f3b44>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0muber_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muber_csv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\PythonData\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    683\u001b[0m         )\n\u001b[0;32m    684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\PythonData\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\PythonData\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\PythonData\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1135\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1136\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\PythonData\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1904\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1905\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1906\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1907\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1908\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'Resources/uber-rides-dataset.csv' does not exist: b'Resources/uber-rides-dataset.csv'"
     ]
    }
   ],
   "source": [
    "uber_df = pd.read_csv(uber_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uber_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uber_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the Columns we need\n",
    "distance_type = uber_df.loc[:, [\"distance_kms\", \"price_usd\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the bins in which the distances will be held\n",
    "bins = [0, 5, 10, 15, 20, 47]\n",
    "#Create the names for the 5 bins\n",
    "distance_names = [\"Very Short Trip\", \"Short Trip\", \"Medium Trip\", \"Long trip\", \"Very Long Trip\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the values to the bins\n",
    "distance_type[\"Type of Distance\"] = pd.cut(distance_type[\"distance_kms\"], bins, labels=distance_names)\n",
    "distance_type.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average price per distance bin\n",
    "avg_price = distance_type.groupby(['Type of Distance'])[\"price_usd\"].mean()\n",
    "avg_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the count per distance bin\n",
    "count = distance_type.groupby(['Type of Distance']).count()\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns into arrays\n",
    "colors = [\"#1f77b4\", \"#ff7f0e\", \"#2ca02c\", \"#d62728\", \"#8c564b\"]\n",
    "explode = (0, 0.1, 0, 0, 0)\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.pie(count.distance_kms, labels=distance_names, explode=explode, colors=colors,\n",
    "autopct='%1.1f%%', shadow=True, startangle=140)\n",
    "plt.title(\"Distribution of distances\")\n",
    "plt.savefig('counttypesoftrip.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above pie chart shows that majority of UBER trips done by the Russian customer is of short distance (5-9Km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot number of trips for each weather description\n",
    "x = uber_df['weather_desc'].value_counts().plot(kind='bar', figsize = (10,6))\n",
    "plt.tight_layout()\n",
    "plt.savefig('weathercount.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above bar chart shows the trip count for each type of weather. We can see that majority of trips were taken during mostly cloudy days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see if there is a correlation between temperature value and distance in kms. \n",
    "x_values = uber_df['temperature_value']\n",
    "y_values = uber_df['distance_kms']\n",
    "correlation = st.pearsonr(x_values, y_values)\n",
    "print(f\"The correlation between both factors is {round(correlation[0],2)}\")\n",
    "(slope, intercept, rvalue, pvalue, stderr) = linregress(x_values, y_values)\n",
    "regress_values = x_values * slope + intercept\n",
    "line_eq = \"y = \" + str(round(slope,2)) + \"x + \" + str(round(intercept,2))\n",
    "plt.scatter(x_values,y_values)\n",
    "plt.plot(x_values,regress_values,\"r-\")\n",
    "plt.annotate(line_eq,(6,10),fontsize=15,color=\"black\")\n",
    "plt.xlabel('Temperature')\n",
    "plt.ylabel('Distance(kms)')\n",
    "print(f\"The r-squared is: {rvalue}\")\n",
    "plt.savefig('tempdistancecorr.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above graph there is no correlation between the temperature value and the distance in kms of Uber trips\n",
    "since the correlation is only 0.08, very close to 0. The r-squared is also near 0 which means that only 7.8% of the\n",
    "variance for the Distance (kms) can be explained by the temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting the sata by weather_desc\n",
    "uber_df = uber_df.sort_values(by='weather_desc', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value counts for weather description\n",
    "weather_count = uber_df.groupby(['weather_desc']).size()\n",
    "weather_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_temp = uber_df.groupby(['weather_desc'])[\"temperature_value\"].mean()\n",
    "avg_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's then calculate the correlation between the trip frequency and the average temperature value\n",
    "x_values = avg_temp\n",
    "y_values = weather_count\n",
    "correlation = st.pearsonr(x_values, y_values)\n",
    "print(f\"The correlation between both factors is {round(correlation[0],2)}\")\n",
    "(slope, intercept, rvalue, pvalue, stderr) = linregress(x_values, y_values)\n",
    "regress_values = x_values * slope + intercept\n",
    "line_eq = \"y = \" + str(round(slope,2)) + \"x + \" + str(round(intercept,2))\n",
    "plt.scatter(x_values,y_values)\n",
    "plt.plot(x_values,regress_values,\"r-\")\n",
    "plt.annotate(line_eq,(6,10),fontsize=15,color=\"black\")\n",
    "plt.xlabel('Average temperature/type of weather')\n",
    "plt.ylabel('Number of trips/type of weather')\n",
    "print(f\"The r-squared is: {rvalue}\")\n",
    "plt.savefig('avgtempweathercorr.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above graph there is no correlation between the trip frequency and the average temperature value\n",
    "since the correlation is only -0.05, very close to 0. The r-squared is also near 0 which means that only 5% of the\n",
    "variance for the trip frequency can be explained by the temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see if there is a correlation between distance and pricing. \n",
    "x_values = uber_df['distance_kms']\n",
    "y_values = uber_df['price_usd']\n",
    "correlation = st.pearsonr(x_values, y_values)\n",
    "print(f\"The correlation between both factors is {round(correlation[0],2)}\")\n",
    "(slope, intercept, rvalue, pvalue, stderr) = linregress(x_values, y_values)\n",
    "regress_values = x_values * slope + intercept\n",
    "line_eq = \"y = \" + str(round(slope,2)) + \"x + \" + str(round(intercept,2))\n",
    "plt.scatter(x_values,y_values)\n",
    "plt.plot(x_values,regress_values,\"r-\")\n",
    "plt.annotate(line_eq,(6,10),fontsize=15,color=\"black\")\n",
    "plt.xlabel('Distance (kms)')\n",
    "plt.ylabel('Trip Price')\n",
    "print(f\"The r-squared is: {rvalue}\")\n",
    "plt.savefig('distanceprice.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above scatter plot there is a moderate correlation between the distance in kms and the trip fare since the correlation number is 0.73, closer to 1. The r-squared is also near 1 which means that 72.6% of the\n",
    "variance for the trip fare can be explained by the distance in kms. The linear equation shows a positive linear regression line between the 2 variables, which means that an increase in the distance in kms corresponds to an increase in the trip fare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pie plot for the vehicle make model\n",
    "vehicle_count = pd.DataFrame(uber_df.groupby([\"vehicle_make_model\"]).count()).reset_index()\n",
    "vehicle_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame down only to those columns to chart\n",
    "vehicle_count = vehicle_count[[\"vehicle_make_model\",\"driver_uid\"]]\n",
    "vehicle_count = vehicle_count.rename(columns={\"driver_uid\": \"Count\"})\n",
    "vehicle_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort data in descending order\n",
    "vehicle_count = vehicle_count.sort_values('Count', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the top 5\n",
    "top_five = vehicle_count[:5].copy()\n",
    "top_five"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other vehicles\n",
    "other_vehicles = pd.DataFrame(data = {\n",
    "    'vehicle_make_model' : ['others'],\n",
    "    'Count' : [vehicle_count['Count'][5:].sum()]\n",
    "})\n",
    "other_vehicles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining top 5 with others\n",
    "top_five_others = pd.concat([top_five, other_vehicles])\n",
    "top_five_others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plotting the 5 top vehicles with the others\n",
    "plt.figure(figsize=(14,10))\n",
    "ax1 = plt.subplot(121, aspect='equal')\n",
    "top_five_others.plot(kind='pie', y = \"Count\", ax=ax1, autopct='%1.1f%%', \n",
    " startangle=200, shadow=False, labels=top_five_others['vehicle_make_model'], legend = False, fontsize=16)\n",
    "plt.savefig('vehicletop5.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above pie chart shows the top 5 vehicle make models used by UBER drivers in Russia. \n",
    "The 1st one is the Hyunday Solaris, a south Korean car, which is sold as Hyundai Accent in the USA. For the Russian market it is assembled by the TagAZ plant in Taganrog.\n",
    "The 2nd one is the Volkswagen Polo, a car produced by the German manufacturer Volkswagen since 1975.\n",
    "The 3rd one is Kia Rio, another South Korean car."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Index to vehicle make model\n",
    "top_five = top_five.set_index(\"vehicle_make_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a bar chart with the same information\n",
    "top_five.plot(kind=\"bar\", figsize=(10,3))\n",
    "\n",
    "# Set a title for the chart\n",
    "plt.title(\"Count per Top 5 Vehicle Make Model\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('vehiclecount.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the columns needed\n",
    "prices_box = uber_df.loc[:, [\"city\", \"price_usd\", \"distance_kms\"]]\n",
    "prices_box[\"price/km\"] = prices_box[\"price_usd\"]/prices_box[\"distance_kms\"]\n",
    "prices_box.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort data by city\n",
    "df = prices_box.sort_values(['city','price/km'],ascending=True).groupby('city').head().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a boxplot to compare prices in the 3 Russian cities\n",
    "df.boxplot(\"price/km\", by=\"city\", figsize=(20, 10))\n",
    "plt.savefig('boxplots.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 3 above boxplots show 3 different distributions of prices/km in the 3 Russian cities.\n",
    "The box plot representing the distribution of prices/km in Saint Petersburg is very short comparted to the other 2, which shows less variability in the data while the boxplot representing prices/km in Moscow shows the highest variability.\n",
    "While the Moscow boxplot shows a symmetric/normal distribution as the median falls in the middle of the Interquartile range, the other 2 boxplots show a very skewed distribution: the Ekaterinburg boxplot is skewed to the right and the Saint Peterburg is skewed to the left.\n",
    "The length of the whiskers indicate data's minimum and maximum.\n",
    "The Saint Petersburg boxplot shows a low outlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract individual groups\n",
    "group1 = prices_box[prices_box[\"city\"] == \"Saint Petersburg\"][\"price_usd\"]\n",
    "group2 = prices_box[prices_box[\"city\"] == \"Moscow\"][\"price_usd\"]\n",
    "group3 = prices_box[prices_box[\"city\"] == \"Ekaterinburg\"][\"price_usd\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import scipy.stats as stats\n",
    "# Perform the ANOVA\n",
    "stats.f_oneway(group1, group2, group3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the p-value is less than 0.05, there is a significant difference between the mean prices of UBER rides in the 3 Russian cities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate IQR of prices in Saint Petersburg\n",
    "quartiles = group1.quantile([.25,.5,.75])\n",
    "lowerq = quartiles[0.25]\n",
    "upperq = quartiles[0.75]\n",
    "iqr = upperq-lowerq\n",
    "\n",
    "print(f\"The lower quartile of prices is: {lowerq}\")\n",
    "print(f\"The upper quartile of prices is: {upperq}\")\n",
    "print(f\"The interquartile range of prices is: {iqr}\")\n",
    "print(f\"The the median of prices is: {quartiles[0.5]} \")\n",
    "\n",
    "lower_bound = lowerq - (1.5*iqr)\n",
    "upper_bound = upperq + (1.5*iqr)\n",
    "print(f\"Values below {lower_bound} could be outliers.\")\n",
    "print(f\"Values above {upper_bound} could be outliers.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate IQR of prices in Moscow\n",
    "quartiles = group2.quantile([.25,.5,.75])\n",
    "lowerq = quartiles[0.25]\n",
    "upperq = quartiles[0.75]\n",
    "iqr = upperq-lowerq\n",
    "\n",
    "print(f\"The lower quartile of prices is: {lowerq}\")\n",
    "print(f\"The upper quartile of prices is: {upperq}\")\n",
    "print(f\"The interquartile range of prices is: {iqr}\")\n",
    "print(f\"The the median of prices is: {quartiles[0.5]} \")\n",
    "\n",
    "lower_bound = lowerq - (1.5*iqr)\n",
    "upper_bound = upperq + (1.5*iqr)\n",
    "print(f\"Values below {lower_bound} could be outliers.\")\n",
    "print(f\"Values above {upper_bound} could be outliers.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate IQR of prices in Ekaterinburg\n",
    "quartiles = group3.quantile([.25,.5,.75])\n",
    "lowerq = quartiles[0.25]\n",
    "upperq = quartiles[0.75]\n",
    "iqr = upperq-lowerq\n",
    "\n",
    "print(f\"The lower quartile of prices is: {lowerq}\")\n",
    "print(f\"The upper quartile of prices is: {upperq}\")\n",
    "print(f\"The interquartile range of prices is: {iqr}\")\n",
    "print(f\"The the median of prices is: {quartiles[0.5]} \")\n",
    "\n",
    "lower_bound = lowerq - (1.5*iqr)\n",
    "upper_bound = upperq + (1.5*iqr)\n",
    "print(f\"Values below {lower_bound} could be outliers.\")\n",
    "print(f\"Values above {upper_bound} could be outliers.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DRIVER GENDER 'driver_gender'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of male and female drivers\n",
    "gender_count = uber_df[\"driver_gender\"].value_counts()\n",
    "\n",
    "# Calculate the percentage of male and female drivers\n",
    "percent_count = round((gender_count)/len(uber_df['driver_gender'])*100,2)\n",
    "\n",
    "# Create a summary table for genders\n",
    "gender_table = pd.DataFrame({\"Gender Count\": gender_count, \"Gender Percentage\":percent_count})\n",
    "gender_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pie chart for genders\n",
    "labels = 'Male', 'Female'\n",
    "sizes = percent_count\n",
    "colors = [\"lightblue\", \"red\"]\n",
    "\n",
    "plt.pie(sizes, labels=labels, colors=colors, shadow=True, autopct='%1.1f%%', startangle=140)\n",
    "plt.title(\"Percentage of Male and Female drivers\")\n",
    "\n",
    "#plt.savefig(\"../Images/percent_gender_pie_chart.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DRIVER FIRST NAME 'driver_name_en'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find drivers first name\n",
    "drivers_names = pd.DataFrame(uber_df['driver_name_en'])\n",
    "\n",
    "# Show duplicates first names\n",
    "drivers_names = drivers_names.groupby(drivers_names.columns.tolist()).size()\n",
    "names_df = pd.DataFrame(drivers_names).reset_index()\n",
    "\n",
    "first_name = names_df['driver_name_en']\n",
    "name_count = names_df[0]\n",
    "\n",
    "# Show table with all the first names\n",
    "names_table = pd.DataFrame({\"First Name\": first_name, \"Name Count\": name_count})\n",
    "names_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a table with the 15 most popular first names among Uber drivers \n",
    "top_names = names_table.nlargest(15,['Name Count']) \n",
    "top_names.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a bar chart with the 15 most popular drivers first name\n",
    "first_names1 = top_names['First Name']\n",
    "total_names1 = np.arange(len(first_names1))\n",
    "popularity1 = top_names['Name Count']\n",
    "\n",
    "plt.bar(total_names1, popularity1, align='center', alpha=0.5, color='green')\n",
    "plt.xticks(total_names1, first_names1)\n",
    "plt.ylabel('Popularity')\n",
    "plt.xlabel('Drivers First Name')\n",
    "plt.title(\"Most popular drivers' first name\")\n",
    "plt.xticks(rotation='vertical')\n",
    "\n",
    "plt.show()\n",
    "#plt.savefig(\"../Images/popular_names_bar_chart.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WAIT TIME 'wait_time'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show wait time and convert to time format \n",
    "wait_df = uber_df['wait_time']\n",
    "wait_df = pd.to_datetime(uber_df['wait_time'])\n",
    "pd.DataFrame(wait_df).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all the trips dates \n",
    "start_df = uber_df['trip_start_time']\n",
    "start_df = pd.to_datetime(start_df).reset_index()\n",
    "start_df\n",
    "\n",
    "trip_number = start_df['index']\n",
    "trip_date = start_df['trip_start_time']\n",
    "\n",
    "# Show table with all the trips and dates\n",
    "trip_dates_df = pd.DataFrame({\"Trip Number\": trip_number, \"Trip Date\": trip_date})\n",
    "trip_dates_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the year and month for each trip \n",
    "trip_dates_df['Year'] = trip_dates_df['Trip Date'].apply(lambda line:  str(line.year))\n",
    "trip_dates_df['Month'] = trip_dates_df['Trip Date'].apply(lambda line:  str(line.month))\n",
    "\n",
    "new_trip_table = pd.DataFrame({\"Trip Number\": trip_number, \n",
    "                               \"Trip Date\": trip_date, \n",
    "                               \"Month\": (trip_dates_df['Month']), \n",
    "                               \"Year\": (trip_dates_df['Year']), \n",
    "                               \"Wait Time by Minutes\": (wait_df.dt.minute)})\n",
    "\n",
    "new_trip_table.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the average wait time per month\n",
    "wait_df_mean = new_trip_table.groupby(['Year','Month'])[\"Wait Time by Minutes\"].mean()\n",
    "pd.DataFrame(wait_df_mean).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the maximum wait time per month\n",
    "wait_df_by_max = new_trip_table.groupby(['Year','Month'])[\"Wait Time by Minutes\"].max()\n",
    "pd.DataFrame(wait_df_by_max).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the minimum wait time per month\n",
    "wait_df_by_min = new_trip_table.groupby(['Year','Month'])[\"Wait Time by Minutes\"].min()\n",
    "pd.DataFrame(wait_df_by_min).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_wait_df = pd.DataFrame({\"Maximum Wait\": (wait_df_by_max), \n",
    "                          \"Average Wait\": (wait_df_mean), \n",
    "                            \"Minimum Wait\": (wait_df_by_min)})\n",
    "pd.DataFrame(all_wait_df).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a line graph showing the average, minimum and maximum wait time for each month\n",
    "all_wait_df.plot(style='-', color =('tab:red', 'orange', 'tab:blue'))\n",
    "\n",
    "plt.xlabel(\"Years (by month)\")\n",
    "plt.ylabel(\"Wait Time (in minutes)\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.title(\"Evolution of Waiting Time over the Years\")\n",
    "plt.grid(axis='y')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.show()\n",
    "#plt.savefig(\"../Images/wait_time_line_chart.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
